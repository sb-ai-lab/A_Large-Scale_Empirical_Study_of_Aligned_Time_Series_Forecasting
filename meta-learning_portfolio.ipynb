{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f01016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.plotting import table \n",
    "import numpy as np\n",
    "import typing as tp\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.stats.stats import kendalltau\n",
    "\n",
    "import dataframe_image as dfi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c542ca",
   "metadata": {},
   "source": [
    "Let's upload the data with the results and build graphs showing the quality of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c8ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = './input_data/results_with_features_relative_to_NaiveForecasterSktime.xlsx'\n",
    "path_to_plots = './results'\n",
    "\n",
    "dataset_name = 'M5'\n",
    "hor = 7\n",
    "metrics = ['MAE', 'MSE', 'RMSE', 'MASE', 'RMSSE', 'SMAPE']\n",
    "sort_metric = 'SMAPE'\n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3fbe591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prep_data(path_to_data):\n",
    "    '''\n",
    "    A function for uploading data\n",
    "    '''\n",
    "    res = pd.read_excel(f'{path_to_data}')\n",
    "    res = res.drop(columns = ['Unnamed: 0'])\n",
    "    res = res.rename(columns = {'model': 'model_name', 'dataset': 'dataset_path'})\n",
    "    ts_lst = list(res['naming_orig'].value_counts().index)\n",
    "    return res\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ff2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_table(res, path_to_plots, dataset_name, hor, metrics, sort_metric, N):\n",
    "    '''\n",
    "    A function for plotting graphs\n",
    "    res - DataFrame with results of experiments (model metrics)\n",
    "    path_to_plots - the path to save the results\n",
    "    dataset_name - name of the dataset or datasets for plotting\n",
    "    hor - horizon of predictions\n",
    "    metrics - metrics to show on the graph\n",
    "    sort_metric - main metrics for sorting\n",
    "    N - number of top models\n",
    "    '''\n",
    "    \n",
    "    res_grouped = res[(res['dataset_path'] == dataset_name)&(res['horizon'] == hor)].groupby(['model_name'])[metrics].agg({'MAE':'mean', 'MSE':'mean', 'RMSE': 'mean', 'MASE':'mean', 'RMSSE':'mean', 'SMAPE': ['mean', 'std']})\n",
    "    pred_time_top_all = res_grouped.sort_values(by = [(sort_metric, 'mean')], ascending = True).rename(columns={\"pred_time\": \"train_time\"}).head(N)\n",
    "    best_N_m = list(pred_time_top_all.head(N).index)\n",
    "    display(pred_time_top_all)\n",
    "    df_styled_all = pred_time_top_all.style.background_gradient().format('{:.3f}')\n",
    "    dfi.export(df_styled_all, path_to_plots + f'results_std_{hor}_' + dataset_name + '.png', fontsize=4, dpi=1000)\n",
    "    \n",
    "    return best_N_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "sort_metric = 'SMAPE'\n",
    "lst_datasets = ['M5', 'favorita_stores_forecasting', 'demand_forecasting_kernels', 'pems04', 'pems08', 'synth_S-AL', 'synth_S-EF', 'synth_S-TSAL', 'synth_S-TSEFAL', 'synth_S-TSEF', 'synth_S-TS', 'synth_S-mTSEF', 'traffic_junctions'] \n",
    "\n",
    "res = load_prep_data(path_to_data)\n",
    "\n",
    "for i in lst_datasets:\n",
    "    for hor in [7, 30, 90, 365]:\n",
    "        plot_metrics_table(res, path_to_plots, i, hor, metrics, sort_metric, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d8ff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naming_orig</th>\n",
       "      <th>horizon</th>\n",
       "      <th>model_name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MASE</th>\n",
       "      <th>RMSSE</th>\n",
       "      <th>SMAPE</th>\n",
       "      <th>dataset_path</th>\n",
       "      <th>...</th>\n",
       "      <th>value__quantile__q_0.75</th>\n",
       "      <th>value__number_peaks__n_1</th>\n",
       "      <th>value__number_peaks__n_3</th>\n",
       "      <th>value__number_peaks__n_5</th>\n",
       "      <th>value__number_peaks__n_10</th>\n",
       "      <th>value__value_count__value_0</th>\n",
       "      <th>value__augmented_dickey_fuller__attr_\"pvalue\"__autolag_\"t-stats\"</th>\n",
       "      <th>value__augmented_dickey_fuller__attr_\"teststat\"__autolag_\"t-stats\"</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M5_sample_1</td>\n",
       "      <td>7</td>\n",
       "      <td>ARIMAEtna</td>\n",
       "      <td>1.018917</td>\n",
       "      <td>0.975314</td>\n",
       "      <td>0.987580</td>\n",
       "      <td>1.018917</td>\n",
       "      <td>0.987580</td>\n",
       "      <td>0.992877</td>\n",
       "      <td>M5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M5_sample_1_TX_HOUSEHOLD.csv</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M5_sample_1</td>\n",
       "      <td>30</td>\n",
       "      <td>ARIMAEtna</td>\n",
       "      <td>1.454314</td>\n",
       "      <td>0.947985</td>\n",
       "      <td>0.973645</td>\n",
       "      <td>1.454314</td>\n",
       "      <td>0.973645</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>M5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M5_sample_1_TX_HOUSEHOLD.csv</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M5_sample_1</td>\n",
       "      <td>90</td>\n",
       "      <td>ARIMAEtna</td>\n",
       "      <td>23.260741</td>\n",
       "      <td>12.036061</td>\n",
       "      <td>3.469303</td>\n",
       "      <td>23.260741</td>\n",
       "      <td>3.469303</td>\n",
       "      <td>0.984611</td>\n",
       "      <td>M5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M5_sample_1_TX_HOUSEHOLD.csv</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M5_sample_1</td>\n",
       "      <td>365</td>\n",
       "      <td>ARIMAEtna</td>\n",
       "      <td>1.689799</td>\n",
       "      <td>0.864922</td>\n",
       "      <td>0.930012</td>\n",
       "      <td>1.689799</td>\n",
       "      <td>0.930012</td>\n",
       "      <td>0.912725</td>\n",
       "      <td>M5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M5_sample_1_TX_HOUSEHOLD.csv</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M5_sample_1</td>\n",
       "      <td>7</td>\n",
       "      <td>ARIMAKats</td>\n",
       "      <td>1.018557</td>\n",
       "      <td>0.975750</td>\n",
       "      <td>0.987801</td>\n",
       "      <td>1.018557</td>\n",
       "      <td>0.987801</td>\n",
       "      <td>0.993005</td>\n",
       "      <td>M5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M5_sample_1_TX_HOUSEHOLD.csv</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   naming_orig  horizon model_name        MAE        MSE      RMSE       MASE  \\\n",
       "0  M5_sample_1        7  ARIMAEtna   1.018917   0.975314  0.987580   1.018917   \n",
       "1  M5_sample_1       30  ARIMAEtna   1.454314   0.947985  0.973645   1.454314   \n",
       "2  M5_sample_1       90  ARIMAEtna  23.260741  12.036061  3.469303  23.260741   \n",
       "3  M5_sample_1      365  ARIMAEtna   1.689799   0.864922  0.930012   1.689799   \n",
       "4  M5_sample_1        7  ARIMAKats   1.018557   0.975750  0.987801   1.018557   \n",
       "\n",
       "      RMSSE     SMAPE dataset_path  ...  value__quantile__q_0.75  \\\n",
       "0  0.987580  0.992877           M5  ...                      0.0   \n",
       "1  0.973645  0.995468           M5  ...                      0.0   \n",
       "2  3.469303  0.984611           M5  ...                      0.0   \n",
       "3  0.930012  0.912725           M5  ...                      0.0   \n",
       "4  0.987801  0.993005           M5  ...                      0.0   \n",
       "\n",
       "   value__number_peaks__n_1  value__number_peaks__n_3  \\\n",
       "0                        80                        34   \n",
       "1                        80                        34   \n",
       "2                        80                        34   \n",
       "3                        80                        34   \n",
       "4                        80                        34   \n",
       "\n",
       "   value__number_peaks__n_5  value__number_peaks__n_10  \\\n",
       "0                        20                         10   \n",
       "1                        20                         10   \n",
       "2                        20                         10   \n",
       "3                        20                         10   \n",
       "4                        20                         10   \n",
       "\n",
       "   value__value_count__value_0  \\\n",
       "0                         1792   \n",
       "1                         1792   \n",
       "2                         1792   \n",
       "3                         1792   \n",
       "4                         1792   \n",
       "\n",
       "   value__augmented_dickey_fuller__attr_\"pvalue\"__autolag_\"t-stats\"  \\\n",
       "0                                                NaN                  \n",
       "1                                                NaN                  \n",
       "2                                                NaN                  \n",
       "3                                                NaN                  \n",
       "4                                                NaN                  \n",
       "\n",
       "   value__augmented_dickey_fuller__attr_\"teststat\"__autolag_\"t-stats\"  \\\n",
       "0                                                NaN                    \n",
       "1                                                NaN                    \n",
       "2                                                NaN                    \n",
       "3                                                NaN                    \n",
       "4                                                NaN                    \n",
       "\n",
       "                   dataset_name  length  \n",
       "0  M5_sample_1_TX_HOUSEHOLD.csv    1941  \n",
       "1  M5_sample_1_TX_HOUSEHOLD.csv    1941  \n",
       "2  M5_sample_1_TX_HOUSEHOLD.csv    1941  \n",
       "3  M5_sample_1_TX_HOUSEHOLD.csv    1941  \n",
       "4  M5_sample_1_TX_HOUSEHOLD.csv    1941  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_prep_data(path_to_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "200ce5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['naming_orig', 'horizon', 'model_name', 'MAE', 'MSE', 'RMSE', 'MASE',\n",
       "       'RMSSE', 'SMAPE', 'dataset_path', 'value__binned_entropy__max_bins_50',\n",
       "       'value__maximum', 'value__minimum', 'value__sample_entropy',\n",
       "       'value__longest_strike_below_mean', 'value__longest_strike_above_mean',\n",
       "       'value__mean_abs_change', 'value__has_duplicate', 'value__sum_values',\n",
       "       'value__mean_change', 'value__median', 'value__mean', 'value__length',\n",
       "       'value__standard_deviation', 'value__variance', 'value__skewness',\n",
       "       'value__kurtosis',\n",
       "       'value__percentage_of_reoccurring_values_to_all_values',\n",
       "       'value__agg_autocorrelation__f_agg_\"mean\"__maxlag_40',\n",
       "       'value__linear_trend__attr_\"pvalue\"',\n",
       "       'value__linear_trend__attr_\"slope\"',\n",
       "       'value__linear_trend__attr_\"intercept\"',\n",
       "       'value__ar_coefficient__coeff_0__k_10',\n",
       "       'value__ar_coefficient__coeff_1__k_10',\n",
       "       'value__ar_coefficient__coeff_2__k_10',\n",
       "       'value__partial_autocorrelation__lag_0',\n",
       "       'value__partial_autocorrelation__lag_1',\n",
       "       'value__partial_autocorrelation__lag_2',\n",
       "       'value__symmetry_looking__r_0.1', 'value__symmetry_looking__r_0.5',\n",
       "       'value__quantile__q_0.25', 'value__quantile__q_0.75',\n",
       "       'value__number_peaks__n_1', 'value__number_peaks__n_3',\n",
       "       'value__number_peaks__n_5', 'value__number_peaks__n_10',\n",
       "       'value__value_count__value_0',\n",
       "       'value__augmented_dickey_fuller__attr_\"pvalue\"__autolag_\"t-stats\"',\n",
       "       'value__augmented_dickey_fuller__attr_\"teststat\"__autolag_\"t-stats\"',\n",
       "       'dataset_name', 'length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb0f5b",
   "metadata": {},
   "source": [
    "# Ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5615fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\medve\\anaconda\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\medve\\anaconda\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\medve\\appdata\\roaming\\python\\python39\\site-packages (from xgboost) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import ndcg_score\n",
    "from scipy.stats.stats import kendalltau\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f'{path_to_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714792e",
   "metadata": {},
   "source": [
    "Features for building a ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = ['model_name', 'value__binned_entropy__max_bins_50', 'value__maximum',\n",
    "       'value__minimum', 'value__sample_entropy',\n",
    "       'value__longest_strike_below_mean', 'value__longest_strike_above_mean',\n",
    "       'value__mean_abs_change', 'value__has_duplicate', 'value__sum_values',\n",
    "       'value__mean_change', 'value__median', 'value__mean', 'value__length',\n",
    "       'value__standard_deviation', 'value__variance', 'value__skewness',\n",
    "       'value__kurtosis',\n",
    "       'value__percentage_of_reoccurring_values_to_all_values',\n",
    "       'value__agg_autocorrelation__f_agg_\"mean\"__maxlag_40',\n",
    "       'value__linear_trend__attr_\"pvalue\"',\n",
    "       'value__linear_trend__attr_\"slope\"',\n",
    "       'value__linear_trend__attr_\"intercept\"',\n",
    "       'value__ar_coefficient__coeff_0__k_10',\n",
    "       'value__ar_coefficient__coeff_1__k_10',\n",
    "       'value__ar_coefficient__coeff_2__k_10',\n",
    "       'value__partial_autocorrelation__lag_0',\n",
    "       'value__partial_autocorrelation__lag_1',\n",
    "       'value__partial_autocorrelation__lag_2',\n",
    "       'value__symmetry_looking__r_0.1', 'value__symmetry_looking__r_0.5',\n",
    "       'value__quantile__q_0.25', 'value__quantile__q_0.75',\n",
    "       'value__number_peaks__n_1', 'value__number_peaks__n_3',\n",
    "       'value__number_peaks__n_5', 'value__number_peaks__n_10',\n",
    "       'value__value_count__value_0',\n",
    "       'value__augmented_dickey_fuller__attr_\"pvalue\"__autolag_\"t-stats\"',\n",
    "       'value__augmented_dickey_fuller__attr_\"teststat\"__autolag_\"t-stats\"',\n",
    "       'length']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae5452",
   "metadata": {},
   "source": [
    "A function for dividing time series into training and test parts. The number of time series in the training sample in the example below is 67 % of the total number of time series. The division of time series occurred randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ea4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "\n",
    "res = df.copy()\n",
    "\n",
    "lst_ts = list(set(res['naming_orig']))\n",
    "ts_train, ts_test = train_test_split(lst_ts, test_size=test_size, random_state=seed)\n",
    "\n",
    "mask_train = []\n",
    "mask_test = []\n",
    "for i in range(len(res['naming_orig'])):\n",
    "    if res['naming_orig'][i] in ts_train:\n",
    "        mask_train.append(True)\n",
    "        mask_test.append(False)\n",
    "    else:\n",
    "        mask_train.append(False)\n",
    "        mask_test.append(True)\n",
    "        \n",
    "data_train = res[mask_train]\n",
    "data_test = res[mask_test]\n",
    "\n",
    "data_train.to_csv('./input_data/ts_train.csv', index = False)\n",
    "data_test.to_csv('./input_data/ts_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b87c1b",
   "metadata": {},
   "source": [
    "Сonsider the forecasting horizon 7. Firstly, selecting data for the appropriate horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./input_data/ts_train.csv')\n",
    "data_test = pd.read_csv('./input_data/ts_test.csv')\n",
    "\n",
    "data_train_7 = data_train[data_train['horizon'] == 7]\n",
    "data_test_7 = data_test[data_test['horizon'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb102694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Rank_model(hor, features_names):\n",
    "    data_train_hor = data_train[data_train['horizon'] == hor]\n",
    "    data_test_hor = data_test[data_test['horizon'] == hor]\n",
    "    data_train_hor['rank'] = data_train_hor.sort_values(['SMAPE'], ascending=True).groupby(['naming_orig'])['SMAPE'].cumcount() + 1\n",
    "    data_test_hor['rank'] = data_test_hor.sort_values(['SMAPE'], ascending=True).groupby(['naming_orig'])['SMAPE'].cumcount() + 1\n",
    "      \n",
    "    # features and target elimination\n",
    "    X_train_hor = data_train_hor.drop(columns = ['rank', 'MAE', 'MSE', 'RMSE', 'MASE', 'RMSSE', 'SMAPE'])\n",
    "    y_train_hor = data_train_hor['rank']\n",
    "    X_test_hor = data_test_hor.drop(columns = ['rank', 'MAE', 'MSE', 'RMSE', 'MASE', 'RMSSE', 'SMAPE'])\n",
    "    y_test_hor = data_test_hor['rank']\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    label_encoded_X_train_hor = X_train_hor.drop(columns = ['naming_orig']).copy()\n",
    "    label_encoded_X_test_hor = X_test_hor.drop(columns = ['naming_orig']).copy()\n",
    "    \n",
    "    for col in label_encoded_X_train_hor[features_names].select_dtypes(include='O').columns:\n",
    "        label_encoded_X_train_hor[col]=le.fit_transform(label_encoded_X_train_hor[col])\n",
    "        label_encoded_X_test_hor[col]=le.transform(label_encoded_X_test_hor[col])\n",
    "        \n",
    "    # division into groups\n",
    "    groups = np.array([35]* len(X_train_7['naming_orig'].value_counts().index))\n",
    "    \n",
    "    # model fitting\n",
    "    model = xgb.XGBRanker(max_depth=5, learning_rate=0.01, n_estimators=3000, n_jobs=-1, colsample_bytree=0.1)\n",
    "    model.fit(label_encoded_X_train_hor[features_names], y_train_hor, group = groups, verbose=True)\n",
    "    feature_importance = model.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    print(f'Важность признаков (горизонт {hor})')\n",
    "    plot_importance(model)\n",
    "    plt.title(f'Важность признаков (горизонт {hor})')\n",
    "        \n",
    "        \n",
    "    # train-test predictions\n",
    "    y_pred_hor_train = model.predict(label_encoded_X_train_hor[features_names])\n",
    "    y_pred_hor_test = model.predict(label_encoded_X_test_hor[features_names])\n",
    "    \n",
    "    # concatinating of the forecasts\n",
    "    pred_rank_hor_train = pd.concat([X_train_hor.reset_index(), pd.DataFrame(y_pred_hor_train).reset_index()], axis = 1)\n",
    "    pred_rank_hor_test = pd.concat([X_test_hor.reset_index(), pd.DataFrame(y_pred_hor_test).reset_index()], axis = 1)\n",
    "    \n",
    "    pred_rank_hor_test['rank'] = pred_rank_hor_test.sort_values([0], ascending=True).groupby(['naming_orig'])[0].cumcount() + 1\n",
    "    display(pred_rank_hor_test.head(1))\n",
    "    \n",
    "    SMAPE_mean_test = pred_rank_hor_test[pred_rank_hor_test['rank'] == 1]['SMAPE'].mean()\n",
    "    print('SMAPE mean test: ', SMAPE_mean_test)\n",
    "    \n",
    "    return SMAPE_mean_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d7249",
   "metadata": {},
   "source": [
    "Data preparation stage: sample was divided into train and test part in the ratio 40:60. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Rank_model(7, features_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff25c9",
   "metadata": {},
   "source": [
    "Example of data splitting for horizon 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5becea",
   "metadata": {},
   "source": [
    "# Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01218319",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RESULTS = './results'\n",
    "METRICS = ['MAE','MSE','SMAPE']\n",
    "METRIC = 'SMAPE'\n",
    "DATASETS = ['M5', 'favorita_stores_forecasting', 'demand_forecasting_kernels', 'pems04', 'pems08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataFrameResDataValidata(path: str = PATH_TO_RESULTS,\n",
    "                                metrics: list[str] = METRICS,\n",
    "                                dataset: tp.Optional[list[str]] = None) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''\n",
    "    The function of preparing the source table for further work.\n",
    "    path - is the path to the pd.Data Frame (scv) data. The data must contain the following fields:\n",
    "    dataset_name, model_name, split, naming_orig, horizon,\n",
    "    also, the data for the split (validation, test) part must contain a Prophet\n",
    "    metrics - a list of metrics that we take into account (you can add everything)\n",
    "    dataset - a list of the names of the datasets that the portfolio is based on.\n",
    "    We leave only those rows that are from dataset datasets.\n",
    "    '''\n",
    "    all_data = pd.read_csv(path).rename(columns={'dataset_name': 'dataset'})\n",
    "    all_data.drop_duplicates(subset=['model_name', 'split', 'naming_orig', 'dataset', 'horizon'], inplace=True)\n",
    "    \n",
    "    all_data = all_data if dataset is None else all_data.loc[all_data.dataset.apply(lambda x: x in dataset)]\n",
    "    \n",
    "    val = all_data.query(f\"split == 'validation'\")\n",
    "    test = all_data.query(f\"split == 'test'\")\n",
    "\n",
    "    val = val.set_index(['model_name', 'naming_orig']).sort_index()\n",
    "    val.fillna(val.mean(level=0), inplace=True)\n",
    "    val.reset_index(inplace=True)\n",
    "    test = test.set_index(['model_name', 'naming_orig']).sort_index()\n",
    "    test.fillna(test.mean(level=0), inplace=True)\n",
    "    test.reset_index(inplace=True)\n",
    "\n",
    "    return val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPortfolioMatrix(data: pd.DataFrame,\n",
    "                       horizon: int,\n",
    "                       metric: list[str] = METRIC,\n",
    "                       metrics: str = METRICS,\n",
    "                       ) -> pd.DataFrame:\n",
    "    '''\n",
    "    The function of converting the data table to the model/score table on a time series\n",
    "    data - prepared table of normalized time series results \n",
    "           (after function GetDataFrameResDataValidata)\n",
    "    horizon - the section on which forecasting horizon will be made\n",
    "    metric - the main metric from the metrics list, according to which the final table for the algorithm will be compiled.\n",
    "    metrics - the list of metrics that we take into account (you can specify all of them)\n",
    "    '''\n",
    "    fillna = data.query(\"model_name == 'Prophet'\").mean(numeric_only=True).loc[metric]\n",
    "    data_horizon = data \\\n",
    "                    .set_index(['model_name', 'dataset', 'naming_orig']) \\\n",
    "                    [metrics].stack().unstack(level=1).unstack(level=1)\n",
    "\n",
    "    data_metric = data_horizon.loc[(slice(None), metric), :].sort_index()\n",
    "    return data_metric.fillna(fillna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPortfolioConstructionMin:\n",
    "    def __init__(\n",
    "      self,\n",
    "      number: int = 3 \n",
    "        ):\n",
    "        self._number = number\n",
    "        self._matrix = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _rebalance(\n",
    "            matrix: np.array,\n",
    "            row_number: int\n",
    "            ) -> np.array:\n",
    "        currency_row = matrix[row_number]\n",
    "        rebalance_matrix = np.minimum(matrix, currency_row)\n",
    "        return rebalance_matrix\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        matrix: np.array\n",
    "        ) -> list[int]:\n",
    "        self._matrix = matrix\n",
    "        portfolio = []\n",
    "        for step in range(self._number):\n",
    "            best_row = np.argmin(np.mean(matrix, axis=1))\n",
    "            matrix = self._rebalance(matrix, best_row)\n",
    "            portfolio.append(best_row)\n",
    "            matrix[portfolio] = np.inf\n",
    "\n",
    "        selected_models_by_ts = np.argmin(self._matrix[portfolio], axis=0).tolist()\n",
    "        return portfolio, selected_models_by_ts\n",
    "\n",
    "    def score(\n",
    "        self,\n",
    "        portfolio: tp.List[int]\n",
    "        ) -> float:\n",
    "        return np.min(self._matrix[portfolio], axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f611ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PortfolioConstriction(alghoritm,\n",
    "                          horizons,\n",
    "                          metric = METRIC,\n",
    "                          numbers = None,\n",
    "                          plot = True,\n",
    "                          dataset = None):\n",
    "    portfolio_dict = {}\n",
    "    pypline_dict = {}\n",
    "    train, test = GetDataFrameResDataValidata(dataset=dataset)\n",
    "\n",
    "    for horizon in horizons:\n",
    "        portfolio_dict[horizon] = {'models': [],\n",
    "                                   'score': [],\n",
    "                                   'number': [],\n",
    "                                   'model_by_ts': [],\n",
    "                                  }\n",
    "        pypline_dict[horizon] = {'models': [],\n",
    "                                 'number': [],\n",
    "                                 'model_by_ts': [],\n",
    "                                }\n",
    "\n",
    "        matrix_frame = GetPortfolioMatrix(train, horizon, metric=metric)\n",
    "        \n",
    "        # oracle - ideal portfolio\n",
    "        oracle = matrix_frame.min(axis=0).mean()\n",
    "        matrix = matrix_frame.values\n",
    "    \n",
    "        numbers = range(1, matrix.shape[0] + 1, 1) if numbers is None else numbers\n",
    "        for number in numbers:\n",
    "            model = alghoritm(number=number)\n",
    "            portfolio, selected_models_by_ts = model.predict(matrix)\n",
    "            score = model.score(portfolio)\n",
    "\n",
    "            portfolio_dict[horizon]['models'].append(matrix_frame.iloc[portfolio].reset_index()['model_name'].values.tolist())\n",
    "            portfolio_dict[horizon]['score'].append(score)\n",
    "            portfolio_dict[horizon]['number'].append(number)\n",
    "            portfolio_dict[horizon]['model_by_ts'].append(selected_models_by_ts)\n",
    "            \n",
    "            pypline_portfolio = [np.random.choice(matrix_frame.shape[0], number, replace=False).tolist() for i in range(100)]\n",
    "            selected_models_by_ts_pypline = [np.argmin(matrix_frame.iloc[portfolio].values, axis=0).tolist() for portfolio in pypline_portfolio]\n",
    "            pypline_dict[horizon]['models'].append([matrix_frame.iloc[portfolio].reset_index()['model_name'].values.tolist() for portfolio in pypline_portfolio])\n",
    "            pypline_dict[horizon]['number'].append(number)\n",
    "            pypline_dict[horizon]['model_by_ts'].append(selected_models_by_ts_pypline)\n",
    "\n",
    "\n",
    "        if plot: \n",
    "            x = np.array(portfolio_dict[horizon]['number'], dtype='int')\n",
    "            plt.figure(figsize=(12, 5), layout='constrained')\n",
    "            plt.xticks(x)\n",
    "            plt.plot(x, np.array(portfolio_dict[horizon]['score']), label='portfolio_score')\n",
    "            plt.xlabel('Number of models in the portfolio')\n",
    "            plt.ylabel(f'{metric} score by portfolio')\n",
    "            plt.hlines(oracle,\n",
    "                    xmin=1,\n",
    "                    xmax=x[-1],\n",
    "                    colors='r',\n",
    "                    label='oracle')\n",
    "            plt.title(f'The Score ({metric}) by the number of models in portfolio on the Validation. The horizon {horizon}')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    return portfolio_dict, pypline_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefce16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTestPortfolio(dict_portfolio,\n",
    "                     pypeline = None,\n",
    "                     metric = METRIC,\n",
    "                     dataset = None,\n",
    "                     plot_pypline = True,\n",
    "                     plot = False):\n",
    "    horizons = [int(key) for key in dict_portfolio.keys()]\n",
    "    \n",
    "    train, test = GetDataFrameResDataValidata(dataset=dataset)\n",
    "\n",
    "    portfolio_dict = {}\n",
    "    for horizon in horizons:\n",
    "        portfolio_dict[horizon] = {'models': [],\n",
    "                                   'score': [],\n",
    "                                   'number': [],\n",
    "                                  }\n",
    "    matrix_frame = GetPortfolioMatrix(test, horizon, metric)\n",
    "\n",
    "    score = []\n",
    "    score_pypline_mean = []\n",
    "    score_pypline_std = []\n",
    "\n",
    "    for idx, number in zip(range(len(dict_portfolio[horizon]['number'])), dict_portfolio[horizon]['number']):\n",
    "\n",
    "        selected_models = matrix_frame.loc[dict_portfolio[horizon]['models'][idx]].values\n",
    "        ind = np.array(dict_portfolio[horizon]['model_by_ts'][idx]).reshape(1, -1)\n",
    "        currency_score = np.take_along_axis(selected_models, ind, axis=0).mean()\n",
    "        score.append(currency_score)\n",
    "\n",
    "        if pypeline is None:\n",
    "            pypeline = np.array([matrix_frame.iloc[np.random.choice(matrix_frame.shape[0],\n",
    "                                                                    number,\n",
    "                                                                    replace=False)].min(axis=0).mean() for i in range(100)])\n",
    "            score_pypline_mean.append(pypeline.mean())\n",
    "            score_pypline_std.append(pypeline.std())\n",
    "        else:\n",
    "            currency_score_pypline = []\n",
    "            for index, portfolio_pypline in enumerate(pypeline[horizon]['models'][idx]):\n",
    "                selected_models_pypline = matrix_frame.loc[portfolio_pypline].values\n",
    "                ind_pypline = np.array(pypeline[horizon]['model_by_ts'][idx][index]).reshape(1, -1)\n",
    "                pypline_index_score = np.take_along_axis(selected_models_pypline, ind_pypline, axis=0).mean()\n",
    "                currency_score_pypline.append(pypline_index_score)\n",
    "            score_pypline_mean.append(np.array(currency_score_pypline).mean())\n",
    "            score_pypline_std.append(np.array(currency_score_pypline).std())\n",
    "\n",
    "        portfolio_dict[horizon]['models'].append(dict_portfolio[horizon]['models'][idx])\n",
    "        portfolio_dict[horizon]['score'].append(currency_score)\n",
    "        portfolio_dict[horizon]['number'].append(number)\n",
    "\n",
    "    oracle = matrix_frame.min(axis=0).mean()\n",
    "    best_model = matrix_frame.iloc[np.argmin(np.mean(matrix_frame.values, axis=1))].mean()\n",
    "\n",
    "    score_pypline_mean = np.array(score_pypline_mean)\n",
    "    score_pypline_std = np.array(score_pypline_std)\n",
    "    if plot:\n",
    "        x = np.array(dict_portfolio[horizon]['number'], dtype='int')\n",
    "        plt.figure(figsize=(12, 5), layout='constrained')\n",
    "        plt.xticks(x)\n",
    "        plt.plot(x, np.array(score), label='portfolio_score')\n",
    "        plt.xlabel('Number of models in the portfolio')\n",
    "        plt.ylabel(f'{metric} score by portfolio')\n",
    "        plt.hlines(oracle,\n",
    "                  xmin=1,\n",
    "                  xmax=x[-1],\n",
    "                  colors='r',\n",
    "                  label=f'oracle, score = ' + '{:.3f}'.format(oracle))\n",
    "        plt.hlines(best_model,\n",
    "              xmin=1,\n",
    "              xmax=x[-1],\n",
    "              colors='y',\n",
    "              label=f'best model on the test, score = ' + '{:.3f}'.format(best_model))\n",
    "        \n",
    "        prophet_mean = test.query(f\"model_name == 'Prophet'\").mean(numeric_only=True).loc[metric]\n",
    "        plt.hlines(np.ones_like(best_model) * prophet_mean,\n",
    "              xmin=1,\n",
    "              xmax=x[-1],\n",
    "              colors='r',\n",
    "              label=f'Prophet test, score = ' + '{:.3f}'.format(prophet_mean))\n",
    "        if plot_pypline:\n",
    "            plt.errorbar(x,\n",
    "                      score_pypline_mean,\n",
    "                      yerr=np.minimum(score_pypline_std, 1),\n",
    "                      label='random_choice_portfolio_mean_and_std',\n",
    "                      ecolor='g',)\n",
    "        plt.title(f'The Score ({metric}) by the number of models in portfolio on the test. The horizon {horizon}')\n",
    "        plt.legend()\n",
    "    return portfolio_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7625995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = set()\n",
    "\n",
    "for number in range(0, len(DATASETS)):\n",
    "    for dataset in combinations(DATASETS, number + 1):\n",
    "        print(dataset)\n",
    "        greedy_portfolio_min_smape, pypeline_min_smape = PortfolioConstriction(GreedyPortfolioConstructionMin,\n",
    "                                                            [30],\n",
    "                                                            numbers=list(range(1, 10)),\n",
    "                                                            metric=METRIC,\n",
    "                                                            dataset=dataset,\n",
    "                                                            plot=False,\n",
    "                                                            )\n",
    "        greedy_portfolio_min_test = GetTestPortfolio(greedy_portfolio_min_smape,\n",
    "                                             pypeline=pypeline_min_smape,\n",
    "                                             metric=METRIC,\n",
    "                                             dataset=dataset,\n",
    "                                             plot_pypline=False\n",
    "                                             )\n",
    "        best_combination = np.array(greedy_portfolio_min_test[30]['score']).argmin()\n",
    "        print(greedy_portfolio_min_test[30]['models'][best_combination])\n",
    "        result.update(greedy_portfolio_min_test[30]['models'][best_combination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a343fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_portfolio_min_smape, pypeline_min_smape = PortfolioConstriction(GreedyPortfolioConstructionMin,\n",
    "                                                            [30],\n",
    "                                                            numbers=list(range(1, 10)),\n",
    "                                                            metric=METRIC,\n",
    "                                                            dataset=DATASETS,\n",
    "                                                            plot=True,\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c845ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f856b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
